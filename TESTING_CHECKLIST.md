# LocalLLM動作確認チェックリスト

## ✅ サーバー起動確認

- ✅ Next.jsサーバー起動完了
- ✅ ポート3000でリクエスト処理中
- ✅ GET / 200 レスポンス成功

## 🔍 動作確認項目

### 1. ブラウザでの基本動作

#### アクセス確認
- [ ] `http://127.0.0.1:3000` にアクセスできる
- [ ] トップページが表示される
- [ ] エラーメッセージが表示されない

#### ログイン機能
- [ ] ログイン画面が表示される
- [ ] ユーザー名を入力してログインできる
- [ ] ログイン後にメイン画面が表示される

### 2. LocalLLM分類機能の確認

#### 基本分類テスト
- [ ] 実習記録を入力（例：「患者さんと話をして、コミュニケーションの重要性を学びました」）
- [ ] 「送信」ボタンをクリック
- [ ] 分類結果が1-12のカテゴリで返ってくる
- [ ] レスポンス時間が3-5秒程度
- [ ] 分類理由が日本語で表示される

#### 期待される動作
- **入力例1**: 「患者さんと話をして、コミュニケーションの重要性を学びました」
  - **期待される分類**: カテゴリ8（コミュニケーション）
  
- **入力例2**: 「血圧測定を初めて行いました」
  - **期待される分類**: カテゴリ4（診察・手技）

- **入力例3**: 「チーム医療の重要性を実感しました」
  - **期待される分類**: カテゴリ7（多職種連携）

### 3. 長文対応の確認

#### 要素分解テスト
- [ ] 200文字以上の長文を入力
- [ ] 複数の要素に分解される
- [ ] 各要素が個別に分類される
- [ ] 要素が適切に表示される

#### テスト用長文例
```
今日は地域医療の現場を訪問しました。まず、在宅医療の実際を見学し、患者さんと家族の関係性について学びました。その後、地域包括ケアシステムについて説明を受け、多職種連携の重要性を実感しました。また、保健・福祉制度についても詳しく知ることができ、医療の社会的役割について理解を深めました。
```

### 4. レポート生成の確認

#### レポート生成テスト
- [ ] 10件以上の投稿がある状態にする
- [ ] レポート生成ボタンをクリック
- [ ] レポートが300-400文字で生成される
- [ ] レポート内容が適切な日本語で生成される
- [ ] レスポンス時間が10-15秒程度

### 5. エラー確認

#### ブラウザコンソール
- [ ] F12で開発者ツールを開く
- [ ] Consoleタブでエラーがないか確認
- [ ] NetworkタブでAPI呼び出しが成功しているか確認

#### サーバーログ
- [ ] PowerShellウィンドウでエラーメッセージがないか確認
- [ ] LocalLLM API呼び出しが成功しているか確認

### 6. パフォーマンス確認

#### レスポンス時間
- [ ] 分類: 3-5秒以内
- [ ] 要素分解: 5-10秒以内
- [ ] レポート生成: 10-15秒以内

#### GPU使用率（オプション）
- [ ] タスクマネージャーでGPU使用率を確認
- [ ] GPUが正常に使用されているか確認

## 🐛 トラブルシューティング

### 問題1: 分類結果が返ってこない

**確認事項**:
- ブラウザのコンソールでエラーメッセージを確認
- サーバーのログでエラーメッセージを確認
- Ollamaが起動しているか確認（`ollama list`）

### 問題2: 分類結果が不正確

**確認事項**:
- プロンプトが正しく送信されているか確認
- モデルの応答を直接確認（`ollama run qwen2.5:7b`）

### 問題3: レスポンスが遅い

**確認事項**:
- GPUが正常に動作しているか確認
- モデルが正しくロードされているか確認

## 📊 期待されるAPIレスポンス

### 分類API (`/api/classify-advanced`)

**リクエスト**:
```json
{
  "text": "患者さんと話をして、コミュニケーションの重要性を学びました"
}
```

**レスポンス**:
```json
{
  "isMultiple": false,
  "category": 8,
  "reason": "LocalLLM分類: カテゴリ8",
  "confidence": 0.8
}
```

### レポート生成API (`/api/generate-report`)

**リクエスト**:
```json
{
  "posts": [
    { "text": "...", "category": 8 },
    ...
  ]
}
```

**レスポンス**:
```json
{
  "report": "実習期間中に10件の記録を残し..."
}
```

## ✅ 確認完了後の次のステップ

すべての項目が正常に動作することを確認したら：

1. ✅ LocalLLM実装完了
2. ✅ 動作確認完了
3. ⏳ 本番環境へのデプロイ準備（必要に応じて）

---

**作成日**: 2025年12月2日
**ステータス**: サーバー起動完了、動作確認中

